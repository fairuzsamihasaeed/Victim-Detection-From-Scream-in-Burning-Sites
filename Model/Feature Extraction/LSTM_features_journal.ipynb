{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select directory of the audio files folder\n",
    "Directory = r'C:/Users/fairu/Desktop/dataset/final sets/alarms'\n",
    "\n",
    "#list of audio files name in that directory\n",
    "file_list = os.listdir(Directory)\n",
    "# file_list.remove('desktop.ini')\n",
    "\n",
    "#starting from 0 files\n",
    "num_frames=[] #different audio length duration\n",
    "i = 0\n",
    "for filename in file_list:\n",
    "    aud, sr = librosa.load(Directory+'/'+file_list[i], sr=16000)\n",
    "    #taking average mfcc's for single file\n",
    "    mfcc = librosa.feature.mfcc(y=aud, sr=16000, n_mfcc=13, n_fft=512, hop_length=256, window = 'hamming')\n",
    "    num_frames.insert(i, mfcc.shape[1])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3060"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_frames)    #number of frames is an array showing the number of frames in each alarm file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat the same process to get all number of frames in other class folders (scream, background, conversation, glass breaking)\n",
    "\n",
    "#select directory of the audio files folder\n",
    "Directory = r'C:/Users/fairu/Desktop/dataset/final sets/background'\n",
    "\n",
    "#list of audio files name in that directory\n",
    "file_list = os.listdir(Directory)\n",
    "# file_list.remove('desktop.ini')\n",
    "\n",
    "#starting from 0 files\n",
    "num_frames_2=[] #different audio length duration\n",
    "i = 0\n",
    "for filename in file_list:\n",
    "    aud, sr = librosa.load(Directory+'/'+file_list[i], sr=16000)\n",
    "    #taking average mfcc's for single file\n",
    "    mfcc = librosa.feature.mfcc(y=aud, sr=16000, n_mfcc=13, n_fft=512, hop_length=256, window = 'hamming')\n",
    "    num_frames_2.insert(i, mfcc.shape[1])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select directory of the audio files folder\n",
    "Directory = r'C:/Users/fairu/Desktop/dataset/final sets/conversation'\n",
    "\n",
    "#list of audio files name in that directory\n",
    "file_list = os.listdir(Directory)\n",
    "# file_list.remove('desktop.ini')\n",
    "\n",
    "#starting from 0 files\n",
    "num_frames_3=[] #different audio length duration\n",
    "i = 0\n",
    "for filename in file_list:\n",
    "    aud, sr = librosa.load(Directory+'/'+file_list[i], sr=16000)\n",
    "    #taking average mfcc's for single file\n",
    "    mfcc = librosa.feature.mfcc(y=aud, sr=16000, n_mfcc=13, n_fft=512, hop_length=256, window = 'hamming')\n",
    "    num_frames_3.insert(i, mfcc.shape[1])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select directory of the audio files folder\n",
    "Directory = r'C:/Users/fairu/Desktop/dataset/final sets/glass breaking'\n",
    "\n",
    "#list of audio files name in that directory\n",
    "file_list = os.listdir(Directory)\n",
    "# file_list.remove('desktop.ini')\n",
    "\n",
    "#starting from 0 files\n",
    "num_frames_4=[] #different audio length duration\n",
    "i = 0\n",
    "for filename in file_list:\n",
    "    aud, sr = librosa.load(Directory+'/'+file_list[i], sr=16000)\n",
    "    #taking average mfcc's for single file\n",
    "    mfcc = librosa.feature.mfcc(y=aud, sr=16000, n_mfcc=13, n_fft=512, hop_length=256, window = 'hamming')\n",
    "    num_frames_4.insert(i, mfcc.shape[1])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select directory of the audio files folder\n",
    "Directory = r'C:/Users/fairu/Desktop/dataset/final sets/scream'\n",
    "\n",
    "#list of audio files name in that directory\n",
    "file_list = os.listdir(Directory)\n",
    "# file_list.remove('desktop.ini')\n",
    "\n",
    "#starting from 0 files\n",
    "num_frames_5=[] #different audio length duration\n",
    "i = 0\n",
    "for filename in file_list:\n",
    "    aud, sr = librosa.load(Directory+'/'+file_list[i], sr=16000)\n",
    "    #taking average mfcc's for single file\n",
    "    mfcc = librosa.feature.mfcc(y=aud, sr=16000, n_mfcc=13, n_fft=512, hop_length=256, window = 'hamming')\n",
    "    num_frames_5.insert(i, mfcc.shape[1])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_num_frames = statistics.median(num_frames)         #finding the median number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_num_frames_2 = statistics.median(num_frames_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_num_frames_3 = statistics.median(num_frames_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_num_frames_4 = statistics.median(num_frames_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_num_frames_5 = statistics.median(num_frames_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_num_frames     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_num_frames_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_num_frames_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_num_frames_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_num_frames_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (126+126+128+77+85)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108.4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a                      #Rounding this up, the median number of frames has been selected to be 110 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction starts from here\n",
    "median_num_frames = 110\n",
    "Directory = r'C:/Users/fairu/Desktop/dataset/final sets/conversation'\n",
    "file_list = os.listdir(Directory)\n",
    "file_list.remove('desktop.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2898"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a dummy Numpy array (row vector)\n",
    "result_array = np.empty([1, (16*median_num_frames)+1])\n",
    "i=0\n",
    "\n",
    "# Loop for feature extraction.\n",
    "for filename in file_list:\n",
    "    #Librosa features\n",
    "    aud, sr = librosa.load(Directory+'/'+file_list[i], sr=16000)\n",
    "    #taking average mfcc's for single file\n",
    "    mfcc = librosa.feature.mfcc(y=aud, sr=16000, n_mfcc=13, n_fft=512, hop_length=256, window = 'hamming')\n",
    "    #taking ZCR\n",
    "    zcr = librosa.feature.zero_crossing_rate(aud, frame_length=512, hop_length=256)\n",
    "    #taking centroid\n",
    "    centroid = librosa.feature.spectral_centroid(y=aud, sr=16000, n_fft=512, hop_length=256, window='hann', center=True, pad_mode='reflect')\n",
    "    #RMS energy - 1 feature per audio file\n",
    "    RMSE = librosa.feature.rms(y=aud, frame_length=512, hop_length=256, center=True, pad_mode= 'reflect')\n",
    "        # Append the three 1D arrays into a single 1D array called 'feat'.\n",
    "    feat0 = np.append(mfcc, zcr, axis=0)\n",
    "    feat1 = np.append(feat0, centroid, axis=0)\n",
    "    feat2 = np.append(feat1, RMSE, axis=0)\n",
    "    transp_feat = feat2.T\n",
    "    \n",
    "    #This step is to make all the audio file same length\n",
    "    if transp_feat.shape[0]<median_num_frames:\n",
    "\n",
    "        # If number of frames is smaller than the cap frame number, we pad the array in order to reach our desired dimensions.\n",
    "\n",
    "        # Pad the array so that it matches the cap frame number. The second value in the argument contains two tuples which indicate which way to pad how much.  \n",
    "        transp_feat = np.pad(transp_feat, ((0, median_num_frames-transp_feat.shape[0]), (0,0)), constant_values=0)\n",
    "\n",
    "    elif transp_feat.shape[0]>median_num_frames:\n",
    "\n",
    "        # If number of frames is larger than the cap frame number, we delete rows (frames) which exceed the cap frame number in order to reach our desired dimensions.\n",
    "\n",
    "        # Define a tuple which contains the range of the row indices to delete.\n",
    "        row_del_index = (range(median_num_frames, transp_feat.shape[0], 1))\n",
    "\n",
    "        transp_feat = np.delete(transp_feat, row_del_index, axis=0)\n",
    "\n",
    "    else:\n",
    "        # If number of frames match the cap frame length\n",
    "        transp_feat = transp_feat\n",
    "    \n",
    "    # Transpose again to flip the rows and columns. This is done so that the features become row parameters, making each column an audio frame.\n",
    "    transp2_feat = transp_feat.T\n",
    "\n",
    "    #Flatten the entire 2D Numpy array into 1D Numpy array, [features sample1],[features sample 2]....so on\n",
    "    #lib_feat_flatten = transp2_feat.flatten('C')\n",
    "    \n",
    "    \n",
    "    all_feat_flatten =  transp2_feat.flatten('C')\n",
    "    label = 0      #for scream\n",
    "    # Create a new Numpy array 'sample' to store features along with label\n",
    "    sample = np.insert(all_feat_flatten, obj=18*median_num_frames, values=label)\n",
    "    result_array = np.append(result_array, sample) #1D numpy array\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5742919,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2898, 1981)\n"
     ]
    }
   ],
   "source": [
    "# Convert 1D Numpy array to 2D array. Argument must be a Tuple. i+1 because we have i samples (audio files) plus a dummy row.\n",
    "result_array = np.reshape(result_array, (i+1,-1))\n",
    "\n",
    "# Delete first dummy row from 2D array\n",
    "result_array = np.delete(result_array, 0, 0)\n",
    "\n",
    "# Print final 2D Numpy array \n",
    "print(result_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=result_array)\n",
    "\n",
    "# Reset row (sample) indexing\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Save as CSV file\n",
    "df.to_csv('feature_RNN_conversation.csv')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
